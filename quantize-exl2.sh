./venv/bin/python ./quantize-exl2.py  -i /home/user/.cache/huggingface/hub/models--mlabonne--Meta-Llama-3.1-8B-Instruct-abliterated/snapshots/f10e77583b109f2e581dfe1f118d8f26576cd4de -o ./exl2-cache/ -cf ./llama-3.1-8b-instruct-abliterated-exl2-4.5bpw -b 4.5 -hb 8 -m llama-3.1-8b-abliterated-measurement.json
